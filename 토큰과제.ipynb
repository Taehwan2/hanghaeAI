{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taehwan2/hanghaeAI/blob/main/%ED%86%A0%ED%81%B0%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UeHRwq3aR-bc"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses datasets pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"debasisdotcom/name-entity-recognition-ner-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "1WUgb3oBWMuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QObF2OAzYwLi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = []\n",
        "df = pd.read_csv(path+'/NER dataset.csv', keep_default_na=False, encoding='ISO-8859-1')\n",
        "unique_pos_tags = df['POS'].unique()  # Replace 'POS' with the actual column name for POS\n",
        "num_pos_tags = len(unique_pos_tags)\n",
        "print(num_pos_tags)\n",
        "data = pd.DataFrame(df)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wWzU5j3GOiEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "hbwB-Ys1UM5e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhC_ETFZZRJ2"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  max_len = 400\n",
        "  texts, labels = [], []\n",
        "  for row in batch.iterrows():\n",
        "    texts.append(row['Word']+row['POS'])\n",
        "    labels.append(row['TAG'])\n",
        "  texts = torch.LongTensor(tokenizer(texts, padding=True, truncation=True, max_length=max_len).input_ids)\n",
        "  labels = torch.LongTensor(labels)\n",
        "\n",
        "  return texts, labels\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_data, batch_size=64, shuffle=True, collate_fn=collate_fn\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_data, batch_size=64, shuffle=False, collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTOUG6zqCM6B"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = torch.hub.load('huggingface/pytorch-transformers', 'model', 'distilbert-base-uncased')\n",
        "    self.classifier = nn.Linear(768, 42)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)['attention']\n",
        "    x = self.classifier(x[:, 0])\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "model = TextClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUbpmsuv5Zl0"
      },
      "outputs": [],
      "source": [
        "for param in model.encoder.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgOvJ7nl5b8f"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "lr = 0.001\n",
        "model = model.to('cuda')\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "n_epochs = 50\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  total_loss = 0.\n",
        "  model.train()\n",
        "  for data in train_loader:\n",
        "    model.zero_grad()\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to('cuda'), labels.to('cuda').long()\n",
        "\n",
        "    preds = model(inputs)\n",
        "    loss = loss_fn(preds, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch:3d} | Train Loss: {total_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJYESKJu5jKc"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, dataloader):\n",
        "  cnt = 0\n",
        "  acc = 0\n",
        "\n",
        "  for data in dataloader:\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "\n",
        "    preds = model(inputs)\n",
        "    preds = torch.argmax(preds, dim=-1)\n",
        "\n",
        "    cnt += labels.shape[0]\n",
        "    acc += (labels == preds).sum().item()\n",
        "\n",
        "  return acc / cnt\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  train_acc = accuracy(model, train_loader)\n",
        "  test_acc = accuracy(model, test_loader)\n",
        "  print(f\"=========> Train acc: {train_acc:.3f} | Test acc: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnnmN8VW-2xS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}