{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taehwan2/hanghaeAI/blob/main/Transformer%EA%B8%B0%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace로 영화리뷰 감정 분석 모델 구현하기\n",
        "\n",
        "이번 실습에서는 HuggingFace로 영화리뷰 감정 분석과 같은 text 분류 문제를 위한 모델을 구현합니다.\n",
        "먼저 필요한 library들을 설치하고 import합니다."
      ],
      "metadata": {
        "id": "owTOpkIFX3wb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeHRwq3aR-bc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate accelerate scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "QObF2OAzYwLi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 준비\n",
        "\n",
        "그 다음 감정 분석을 위해 사용할 imdb dataset을 `load_dataset` 함수로 다운로드 받습니다."
      ],
      "metadata": {
        "id": "7vOSyAKGim9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minli = load_dataset(\"nyu-mll/glue\", \"mnli\")\n",
        "minli"
      ],
      "metadata": {
        "id": "HzxfcmYPZA7x",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`load_dataset`은 HuggingFace의 `datasets` library의 함수로, HuggingFace의 hub에서 dataset을 다운로드 받을 수 있도록 만든 함수입니다.\n",
        "출력 결과를 보시면 `imdb`는 `train`, `test`, 그리고 `unsupervised` data로 구성되어있습니다.\n",
        "이 중에서 우리는 `train`과 `test`를 활용합니다.\n",
        "\n",
        "`train` data를 한 번 살펴보겠습니다."
      ],
      "metadata": {
        "id": "BT1VSMq-iuRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minli['train'][0]"
      ],
      "metadata": {
        "id": "9nVFOdAIi4Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train`과 `test`의 각 data는 `text`와 `label`로 구성되어있습니다.\n",
        "각각은 영화리뷰와 해당 영화리뷰의 긍정/부정 여부를 의미합니다.\n",
        "이는 이전 주차들에서 사용한 imdb dataset과 동일합니다.\n",
        "\n",
        "이번에는 tokenizer를 불러와서 미리 text들을 tokenize합니다."
      ],
      "metadata": {
        "id": "6YdYEPD6nXzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "def preprocess_function(data):\n",
        "    text = []\n",
        "    for i in range(len(data['premise'])):\n",
        "        text.append(data['premise'][i] + data['hypothesis'][i])\n",
        "    return tokenizer(text, truncation=True)\n",
        "\n",
        "minli_tokenized = minli.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "BhC_ETFZZRJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer를 실행할 때 넘겨주었던 `truncation` 옵션은 주어진 text가 일정 길이 이상이면 잘라내라는 의미입니다.\n",
        "만약 특정 길이 값이 같이 주어지지 않는다면 `bert-base-cased`를 학습할 때 사용한 text의 최대 길이를 기준으로 값을 결정합니다."
      ],
      "metadata": {
        "id": "ba2jcRcLpjc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minli_tokenized['train'][0].keys()"
      ],
      "metadata": {
        "id": "i1aK6gpPqSSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막 출력 결과를 보면, `text`와 `label` 이외에 `input_ids`가 생기신 것을 확인하실 수 있습니다.\n",
        "이는 우리가 `AutoTokenizer.from_pretrained`로 불러온 tokenizer로 text를 token들로 나누고 정수 index로 변환한 결과입니다.\n",
        "\n",
        "이번에는 `train` data를 쪼개 training data와 validation data를 만들어보겠습니다."
      ],
      "metadata": {
        "id": "Wfq0Ih4hqXYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minli_split = minli_tokenized['train'].train_test_split(test_size=0.2)\n",
        "minli_split2  = minli_split['train'].train_test_split(test_size=0.25)\n",
        "minli_train = minli_split2['train']\n",
        "minli_val = minli_split2['test']\n",
        "minli_test = minli_split['test']"
      ],
      "metadata": {
        "id": "RIXTFBTobI8N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace `datasets`로 불러온 dataset은 `train_test_split`으로 쉽게 쪼갤 수 있습니다.\n",
        "\n",
        "다음은 각 split의 크기입니다."
      ],
      "metadata": {
        "id": "BS1FltWfqjnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(minli_train), len(minli_val), len(minli_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SGfOwadaYlk",
        "outputId": "0b7287e0-6013-41cc-e8fe-1c1d126cb1e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(235620, 78541, 78541)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 구현\n",
        "\n",
        "이번에는 text 분류를 수행할 Transformer를 구현합니다.\n",
        "이전에는 Transformer의 구성 요소들을 직접 구현하여 합쳤습니다.\n",
        "이번에는 HuggingFace의 BERT를 활용하여 인자만 넘겨주는 식으로 구현해보겠습니다:"
      ],
      "metadata": {
        "id": "cGe7Fa9wqrCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig()\n",
        "\n",
        "config.hidden_size = 64  # BERT layer의 기본 hidden dimension\n",
        "config.intermediate_size = 64  # FFN layer의 중간 hidden dimension\n",
        "config.num_hidden_layers = 2  # BERT layer의 개수\n",
        "config.num_attention_heads = 4  # Multi-head attention에서 사용하는 head 개수\n",
        "config.num_labels = 3  # 마지막에 예측해야 하는 분류 문제의 class 개수\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_config(config)"
      ],
      "metadata": {
        "id": "xw-ZdYVCZfxU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT는 이전에 배운 Transformer의 architecture를 그대로 사용합니다.\n",
        "그래서 BERT의 옵션들만 수정하면 vanilla Transformer를 쉽게 구현할 수 있습니다.\n",
        "\n",
        "Transformer 구현 이외에 분류 문제에 맞춰 첫 번째 token을 linear classifier를 거치는 등의 과정은 `AutoModelForSequenceClassification`이 구현해줍니다.\n",
        "즉, 우리가 `config`로 넘겨주는 BERT의 마지막에 linear classifier를 달아주는 역할을 합니다."
      ],
      "metadata": {
        "id": "BQpVs-lirLp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 코드\n",
        "\n",
        "다음은 위에서 구현한 Transformer를 imdb로 학습하는 코드를 구현합니다.\n",
        "먼저 다음과 같이 학습 인자들을 정의합니다."
      ],
      "metadata": {
        "id": "31PYtx_Vrj1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='hf_transformer',  # 모델, log 등을 저장할 directory\n",
        "    num_train_epochs=3,  # epoch 수\n",
        "    per_device_train_batch_size=128,  # training data의 batch size\n",
        "    per_device_eval_batch_size=128,  # validation data의 batch size\n",
        "    logging_strategy=\"epoch\",  # Epoch가 끝날 때마다 training loss 등을 log하라는 의미\n",
        "    do_train=True,  # 학습을 진행하겠다는 의미\n",
        "    do_eval=True,  # 학습 중간에 validation data에 대한 평가를 수행하겠다는 의미\n",
        "    eval_strategy=\"epoch\",  # 매 epoch가 끝날 때마다 validation data에 대한 평가를 수행한다는 의미\n",
        "    save_strategy=\"epoch\",  # 매 epoch가 끝날 때마다 모델을 저장하겠다는 의미\n",
        "    learning_rate=1e-3,  # optimizer에 사용할 learning rate\n",
        "    load_best_model_at_end=True  # 학습이 끝난 후, validation data에 대한 성능이 가장 좋은 모델을 채택하겠다는 의미\n",
        ")"
      ],
      "metadata": {
        "id": "YtqLwO7sZhXT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "각각의 부분들은 이전 주차에서 배웠던 내용들을 설정하는 것에 불과하다는 것을 알 수 있습니다.\n",
        "요약하면 다음과 같습니다:\n",
        "- `epochs`: training data를 몇 번 반복할 것인지 결정합니다.\n",
        "- `batch_size`: training data를 얼마나 잘게 잘라서 학습할 것인지 결정합니다.\n",
        "- `learning_rate`: optimizer의 learning rate를 얼마로 할 것인지 결정합니다.\n",
        "위의 부분들 이외에도 사소한 구현 요소들도 지정할 수 있습니다.\n",
        "\n",
        "다음은 loss 이외의 평가 함수들을 구현하는 방법입니다."
      ],
      "metadata": {
        "id": "rKvB31IlsK2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    predictions, labels = pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "Wa2zYLTUZ8rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`evaluate` 또한 HuggingFace의 library로 다양한 평가 함수들을 제공하고 있습니다.\n",
        "이번 실습의 경우, 감정 분석 문제는 분류 문제이기 때문에 정확도를 계산할 수 있습니다.\n",
        "위와 같이 예측 결과(`pred`)와 실제 label(`labels`)가 주어졌을 때 정확도를 계산하는 것은 `evaluate`의 accuracy 함수로 구현할 수 있습니다.\n",
        "\n",
        "마지막으로 위의 요소들을 종합하여 학습할 수 있는 `Trainer`를 구현합니다."
      ],
      "metadata": {
        "id": "tGENAMKk-4I2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=minli_train,\n",
        "    eval_dataset=minli_val,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    # callbacks = [EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")"
      ],
      "metadata": {
        "id": "Ci4lNfK6Z_z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델, training 인자, training과 validation data, 부가적인 평가 함수, 그리고 tokenizer를 넘겨주면 끝입니다.\n",
        "별개로 early stopping과 같은 기능도 주석 친 부분과 같이 `callbacks`로 구현할 수 있으니 참고해주시길 바랍니다.\n",
        "\n",
        "위와 같이 만든 `Trainer`는 다음과 같이 학습을 할 수 있습니다."
      ],
      "metadata": {
        "id": "MOK4poi1_Mgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init()\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "qmNkWuVVaBEc",
        "outputId": "fd65df7a-6505-41a0-a3c5-ef70f8edbc36"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaehwanjj\u001b[0m (\u001b[33mtaehwanjj-kfr\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250415_132253-gzqynylg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/taehwanjj-kfr/uncategorized/runs/gzqynylg' target=\"_blank\">stellar-dust-2</a></strong> to <a href='https://wandb.ai/taehwanjj-kfr/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/taehwanjj-kfr/uncategorized' target=\"_blank\">https://wandb.ai/taehwanjj-kfr/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/taehwanjj-kfr/uncategorized/runs/gzqynylg' target=\"_blank\">https://wandb.ai/taehwanjj-kfr/uncategorized/runs/gzqynylg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5523' max='5523' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5523/5523 04:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.019200</td>\n",
              "      <td>0.975899</td>\n",
              "      <td>0.511504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.949300</td>\n",
              "      <td>0.962001</td>\n",
              "      <td>0.524134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.891000</td>\n",
              "      <td>0.969631</td>\n",
              "      <td>0.524223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5523, training_loss=0.9531601645604177, metrics={'train_runtime': 295.0135, 'train_samples_per_second': 2396.026, 'train_steps_per_second': 18.721, 'total_flos': 29551792037040.0, 'train_loss': 0.9531601645604177, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "보시다시피 training loss는 잘 떨어지는 반면, validation loss는 중간부터 쭉 올라가는 것을 볼 수 있습니다.\n",
        "Overfitting이 일어났다고 볼 수 있습니다.\n",
        "\n",
        "위와 같이 학습이 끝난 후 validation loss가 가장 낮은 모델을 가지고 test data의 성능을 평가하는 것은 다음과 같이 구현할 수 있습니다."
      ],
      "metadata": {
        "id": "IuGFTHER_a_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(minli_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "16mRdiEgeVPQ",
        "outputId": "96dcaaf4-ba42-4e25-ad55-243fa87b7926"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='614' max='614' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [614/614 00:19]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.9640191793441772,\n",
              " 'eval_accuracy': 0.522593295221604,\n",
              " 'eval_runtime': 19.9707,\n",
              " 'eval_samples_per_second': 3932.812,\n",
              " 'eval_steps_per_second': 30.745,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에 학습 인자에서 `load_best_model_at_end=True`를 넘겨줬기 때문에 `trainer`는 학습이 끝난 후, 기본적으로 validation loss가 가장 좋은 모델을 가지고 `evaluate`를 진행합니다.\n",
        "실제로 결과를 보면 `eval_loss`가 가장 낮은 validation loss와 유사한 것을 볼 수 있습니다.\n",
        "\n",
        "평가할 때 사용한 모델은 다음과 같이 저장할 수 있습니다."
      ],
      "metadata": {
        "id": "h05cUK6N_te4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "kRVBuZ4bl4N1"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}
